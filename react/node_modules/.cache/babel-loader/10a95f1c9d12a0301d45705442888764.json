{"ast":null,"code":"/*\n\tMIT License http://www.opensource.org/licenses/mit-license.php\n\tAuthor Tobias Koppers @sokra\n*/\n\"use strict\";\n\nvar _createForOfIteratorHelper = require(\"C:/myCodes/KredoCodeChallenge/react/node_modules/@babel/runtime/helpers/createForOfIteratorHelper.js\").default;\nvar _classCallCheck = require(\"C:/myCodes/KredoCodeChallenge/react/node_modules/@babel/runtime/helpers/classCallCheck.js\").default;\nvar _createClass = require(\"C:/myCodes/KredoCodeChallenge/react/node_modules/@babel/runtime/helpers/createClass.js\").default;\nvar MergeDuplicateChunksPlugin = /*#__PURE__*/function () {\n  function MergeDuplicateChunksPlugin() {\n    _classCallCheck(this, MergeDuplicateChunksPlugin);\n  }\n  _createClass(MergeDuplicateChunksPlugin, [{\n    key: \"apply\",\n    value: function apply(compiler) {\n      compiler.hooks.compilation.tap(\"MergeDuplicateChunksPlugin\", function (compilation) {\n        compilation.hooks.optimizeChunksBasic.tap(\"MergeDuplicateChunksPlugin\", function (chunks) {\n          // remember already tested chunks for performance\n          var notDuplicates = new Set();\n\n          // for each chunk\n          var _iterator = _createForOfIteratorHelper(chunks),\n            _step;\n          try {\n            for (_iterator.s(); !(_step = _iterator.n()).done;) {\n              var chunk = _step.value;\n              // track a Set of all chunk that could be duplicates\n              var possibleDuplicates = void 0;\n              var _iterator2 = _createForOfIteratorHelper(chunk.modulesIterable),\n                _step2;\n              try {\n                for (_iterator2.s(); !(_step2 = _iterator2.n()).done;) {\n                  var _module = _step2.value;\n                  if (possibleDuplicates === undefined) {\n                    // when possibleDuplicates is not yet set,\n                    // create a new Set from chunks of the current module\n                    // including only chunks with the same number of modules\n                    var _iterator4 = _createForOfIteratorHelper(_module.chunksIterable),\n                      _step4;\n                    try {\n                      for (_iterator4.s(); !(_step4 = _iterator4.n()).done;) {\n                        var dup = _step4.value;\n                        if (dup !== chunk && chunk.getNumberOfModules() === dup.getNumberOfModules() && !notDuplicates.has(dup)) {\n                          // delay allocating the new Set until here, reduce memory pressure\n                          if (possibleDuplicates === undefined) {\n                            possibleDuplicates = new Set();\n                          }\n                          possibleDuplicates.add(dup);\n                        }\n                      }\n                      // when no chunk is possible we can break here\n                    } catch (err) {\n                      _iterator4.e(err);\n                    } finally {\n                      _iterator4.f();\n                    }\n                    if (possibleDuplicates === undefined) break;\n                  } else {\n                    // validate existing possible duplicates\n                    var _iterator5 = _createForOfIteratorHelper(possibleDuplicates),\n                      _step5;\n                    try {\n                      for (_iterator5.s(); !(_step5 = _iterator5.n()).done;) {\n                        var _dup = _step5.value;\n                        // remove possible duplicate when module is not contained\n                        if (!_dup.containsModule(_module)) {\n                          possibleDuplicates.delete(_dup);\n                        }\n                      }\n                      // when all chunks has been removed we can break here\n                    } catch (err) {\n                      _iterator5.e(err);\n                    } finally {\n                      _iterator5.f();\n                    }\n                    if (possibleDuplicates.size === 0) break;\n                  }\n                }\n\n                // when we found duplicates\n              } catch (err) {\n                _iterator2.e(err);\n              } finally {\n                _iterator2.f();\n              }\n              if (possibleDuplicates !== undefined && possibleDuplicates.size > 0) {\n                var _iterator3 = _createForOfIteratorHelper(possibleDuplicates),\n                  _step3;\n                try {\n                  for (_iterator3.s(); !(_step3 = _iterator3.n()).done;) {\n                    var otherChunk = _step3.value;\n                    if (otherChunk.hasRuntime() !== chunk.hasRuntime()) continue;\n                    // merge them\n                    if (chunk.integrate(otherChunk, \"duplicate\")) {\n                      chunks.splice(chunks.indexOf(otherChunk), 1);\n                    }\n                  }\n                } catch (err) {\n                  _iterator3.e(err);\n                } finally {\n                  _iterator3.f();\n                }\n              }\n\n              // don't check already processed chunks twice\n              notDuplicates.add(chunk);\n            }\n          } catch (err) {\n            _iterator.e(err);\n          } finally {\n            _iterator.f();\n          }\n        });\n      });\n    }\n  }]);\n  return MergeDuplicateChunksPlugin;\n}();\nmodule.exports = MergeDuplicateChunksPlugin;","map":{"version":3,"names":["MergeDuplicateChunksPlugin","compiler","hooks","compilation","tap","optimizeChunksBasic","chunks","notDuplicates","Set","chunk","possibleDuplicates","modulesIterable","module","undefined","chunksIterable","dup","getNumberOfModules","has","add","containsModule","delete","size","otherChunk","hasRuntime","integrate","splice","indexOf","exports"],"sources":["C:/myCodes/KredoCodeChallenge/react/node_modules/webpack/lib/optimize/MergeDuplicateChunksPlugin.js"],"sourcesContent":["/*\n\tMIT License http://www.opensource.org/licenses/mit-license.php\n\tAuthor Tobias Koppers @sokra\n*/\n\"use strict\";\n\nclass MergeDuplicateChunksPlugin {\n\tapply(compiler) {\n\t\tcompiler.hooks.compilation.tap(\n\t\t\t\"MergeDuplicateChunksPlugin\",\n\t\t\tcompilation => {\n\t\t\t\tcompilation.hooks.optimizeChunksBasic.tap(\n\t\t\t\t\t\"MergeDuplicateChunksPlugin\",\n\t\t\t\t\tchunks => {\n\t\t\t\t\t\t// remember already tested chunks for performance\n\t\t\t\t\t\tconst notDuplicates = new Set();\n\n\t\t\t\t\t\t// for each chunk\n\t\t\t\t\t\tfor (const chunk of chunks) {\n\t\t\t\t\t\t\t// track a Set of all chunk that could be duplicates\n\t\t\t\t\t\t\tlet possibleDuplicates;\n\t\t\t\t\t\t\tfor (const module of chunk.modulesIterable) {\n\t\t\t\t\t\t\t\tif (possibleDuplicates === undefined) {\n\t\t\t\t\t\t\t\t\t// when possibleDuplicates is not yet set,\n\t\t\t\t\t\t\t\t\t// create a new Set from chunks of the current module\n\t\t\t\t\t\t\t\t\t// including only chunks with the same number of modules\n\t\t\t\t\t\t\t\t\tfor (const dup of module.chunksIterable) {\n\t\t\t\t\t\t\t\t\t\tif (\n\t\t\t\t\t\t\t\t\t\t\tdup !== chunk &&\n\t\t\t\t\t\t\t\t\t\t\tchunk.getNumberOfModules() === dup.getNumberOfModules() &&\n\t\t\t\t\t\t\t\t\t\t\t!notDuplicates.has(dup)\n\t\t\t\t\t\t\t\t\t\t) {\n\t\t\t\t\t\t\t\t\t\t\t// delay allocating the new Set until here, reduce memory pressure\n\t\t\t\t\t\t\t\t\t\t\tif (possibleDuplicates === undefined) {\n\t\t\t\t\t\t\t\t\t\t\t\tpossibleDuplicates = new Set();\n\t\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t\t\tpossibleDuplicates.add(dup);\n\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t// when no chunk is possible we can break here\n\t\t\t\t\t\t\t\t\tif (possibleDuplicates === undefined) break;\n\t\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\t\t// validate existing possible duplicates\n\t\t\t\t\t\t\t\t\tfor (const dup of possibleDuplicates) {\n\t\t\t\t\t\t\t\t\t\t// remove possible duplicate when module is not contained\n\t\t\t\t\t\t\t\t\t\tif (!dup.containsModule(module)) {\n\t\t\t\t\t\t\t\t\t\t\tpossibleDuplicates.delete(dup);\n\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t// when all chunks has been removed we can break here\n\t\t\t\t\t\t\t\t\tif (possibleDuplicates.size === 0) break;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t// when we found duplicates\n\t\t\t\t\t\t\tif (\n\t\t\t\t\t\t\t\tpossibleDuplicates !== undefined &&\n\t\t\t\t\t\t\t\tpossibleDuplicates.size > 0\n\t\t\t\t\t\t\t) {\n\t\t\t\t\t\t\t\tfor (const otherChunk of possibleDuplicates) {\n\t\t\t\t\t\t\t\t\tif (otherChunk.hasRuntime() !== chunk.hasRuntime()) continue;\n\t\t\t\t\t\t\t\t\t// merge them\n\t\t\t\t\t\t\t\t\tif (chunk.integrate(otherChunk, \"duplicate\")) {\n\t\t\t\t\t\t\t\t\t\tchunks.splice(chunks.indexOf(otherChunk), 1);\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t// don't check already processed chunks twice\n\t\t\t\t\t\t\tnotDuplicates.add(chunk);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t);\n\t\t\t}\n\t\t);\n\t}\n}\nmodule.exports = MergeDuplicateChunksPlugin;\n"],"mappings":"AAAA;AACA;AACA;AACA;AACA,YAAY;;AAAC;AAAA;AAAA;AAAA,IAEPA,0BAA0B;EAAA;IAAA;EAAA;EAAA;IAAA;IAAA,OAC/B,eAAMC,QAAQ,EAAE;MACfA,QAAQ,CAACC,KAAK,CAACC,WAAW,CAACC,GAAG,CAC7B,4BAA4B,EAC5B,UAAAD,WAAW,EAAI;QACdA,WAAW,CAACD,KAAK,CAACG,mBAAmB,CAACD,GAAG,CACxC,4BAA4B,EAC5B,UAAAE,MAAM,EAAI;UACT;UACA,IAAMC,aAAa,GAAG,IAAIC,GAAG,EAAE;;UAE/B;UAAA,2CACoBF,MAAM;YAAA;UAAA;YAA1B,oDAA4B;cAAA,IAAjBG,KAAK;cACf;cACA,IAAIC,kBAAkB;cAAC,4CACFD,KAAK,CAACE,eAAe;gBAAA;cAAA;gBAA1C,uDAA4C;kBAAA,IAAjCC,OAAM;kBAChB,IAAIF,kBAAkB,KAAKG,SAAS,EAAE;oBACrC;oBACA;oBACA;oBAAA,4CACkBD,OAAM,CAACE,cAAc;sBAAA;oBAAA;sBAAvC,uDAAyC;wBAAA,IAA9BC,GAAG;wBACb,IACCA,GAAG,KAAKN,KAAK,IACbA,KAAK,CAACO,kBAAkB,EAAE,KAAKD,GAAG,CAACC,kBAAkB,EAAE,IACvD,CAACT,aAAa,CAACU,GAAG,CAACF,GAAG,CAAC,EACtB;0BACD;0BACA,IAAIL,kBAAkB,KAAKG,SAAS,EAAE;4BACrCH,kBAAkB,GAAG,IAAIF,GAAG,EAAE;0BAC/B;0BACAE,kBAAkB,CAACQ,GAAG,CAACH,GAAG,CAAC;wBAC5B;sBACD;sBACA;oBAAA;sBAAA;oBAAA;sBAAA;oBAAA;oBACA,IAAIL,kBAAkB,KAAKG,SAAS,EAAE;kBACvC,CAAC,MAAM;oBACN;oBAAA,4CACkBH,kBAAkB;sBAAA;oBAAA;sBAApC,uDAAsC;wBAAA,IAA3BK,IAAG;wBACb;wBACA,IAAI,CAACA,IAAG,CAACI,cAAc,CAACP,OAAM,CAAC,EAAE;0BAChCF,kBAAkB,CAACU,MAAM,CAACL,IAAG,CAAC;wBAC/B;sBACD;sBACA;oBAAA;sBAAA;oBAAA;sBAAA;oBAAA;oBACA,IAAIL,kBAAkB,CAACW,IAAI,KAAK,CAAC,EAAE;kBACpC;gBACD;;gBAEA;cAAA;gBAAA;cAAA;gBAAA;cAAA;cACA,IACCX,kBAAkB,KAAKG,SAAS,IAChCH,kBAAkB,CAACW,IAAI,GAAG,CAAC,EAC1B;gBAAA,4CACwBX,kBAAkB;kBAAA;gBAAA;kBAA3C,uDAA6C;oBAAA,IAAlCY,UAAU;oBACpB,IAAIA,UAAU,CAACC,UAAU,EAAE,KAAKd,KAAK,CAACc,UAAU,EAAE,EAAE;oBACpD;oBACA,IAAId,KAAK,CAACe,SAAS,CAACF,UAAU,EAAE,WAAW,CAAC,EAAE;sBAC7ChB,MAAM,CAACmB,MAAM,CAACnB,MAAM,CAACoB,OAAO,CAACJ,UAAU,CAAC,EAAE,CAAC,CAAC;oBAC7C;kBACD;gBAAC;kBAAA;gBAAA;kBAAA;gBAAA;cACF;;cAEA;cACAf,aAAa,CAACW,GAAG,CAACT,KAAK,CAAC;YACzB;UAAC;YAAA;UAAA;YAAA;UAAA;QACF,CAAC,CACD;MACF,CAAC,CACD;IACF;EAAC;EAAA;AAAA;AAEFG,MAAM,CAACe,OAAO,GAAG3B,0BAA0B"},"metadata":{},"sourceType":"script"}